# -*- coding: utf-8 -*-
"""Teste4 - Trabalho Pratico I.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yftL9HJuJfAUpVROrJm86ox34lzNnRH1
"""

#import libraries 

import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt

url='https://github.com/Diegojfsr/RNA_Trabalho_Pratico_I/blob/main/test.csv?raw=true'
test = pd.read_csv(url)
url='https://github.com/Diegojfsr/RNA_Trabalho_Pratico_I/blob/main/train.csv?raw=true'
train = pd.read_csv(url)

train

train1 = train.dropna()
train1

#Analyse target

train1['Transported'].replace({False: 0, True: 1},inplace=True)
train1['Transported']

sns.displot(train1['Transported'])

target = train1['Transported']

train1.drop(['Transported'],axis=1, inplace=True)
train1

combi = train1.append(test)
combi

combi.isnull().sum()

#Impute null values

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

imp = IterativeImputer(random_state=42)

date = pd.Timestamp('2200-01-01')

for col in combi:
    if combi[col].dtype=="object":
        combi[col].fillna("not listed", inplace=True)
    if combi[col].dtype=="int":
        #X[col].fillna(X[col].mode()[0], inplace=True)
        combi[col].fillna(combi[col].mean(), inplace=True)
        #combi[col] = combi[col].astype.int()
    if combi[col].dtype=='float':
       #X[col].fillna(X[col].mean(), inplace=True)
       combi[col] = imp.fit_transform(combi[col].values.reshape(-1,1))
    if combi[col].dtype=="datetime64[ns]":
        combi[col].fillna(date, inplace=True)
combi

combi.isnull().sum()

#Home Planet

home_count = combi['HomePlanet'].value_counts()
home_count

combi['HomePlanet'].replace({"Earth": 1, "Europa": 2, "Mars": 3, "not listed": 4},inplace=True)
combi['HomePlanet']

#Cryo Sleep

combi['CryoSleep'][combi['CryoSleep'] == 'not listed'] = False

combi['CryoSleep'].replace({False: 0, True: 1})

combi['CryoSleep'] = combi['CryoSleep'].astype(int)
combi['CryoSleep']

#Destination

dest_count = combi['Destination'].value_counts()
dest_count

dest_percent = dest_count / len(combi)
dest_percent

combi['Destination'].replace({"TRAPPIST-1e": 1, "55 Cancri e": 2, "PSO J318.5-22": 3, "not listed": 4},inplace=True)
combi['Destination']

#Age

combi['Age_group'] = pd.cut(x=combi['Age'], bins=[-1, 18, 40, 65, 100], labels=['child', 'young adult', 'middle age', 'pensioner'])
combi['Age_group']

age_count = combi['Age_group'].value_counts()
age_count

combi['Age_group'].replace({"young adult": 1, "child": 2, "middle age": 3, "pensioner": 4},inplace=True)
combi['Age_group']

combi['Age_group'] = combi['Age_group'].astype(int)
combi

#VIP

combi['VIP'][combi['VIP'] == 'not listed'] = False

combi['VIP'].replace({False: 0, True: 1})

combi['VIP'] = combi['VIP'].astype(int)
combi['VIP']

#Room Service

combi['Room_Service_group'] = pd.cut(x=combi['RoomService'], bins=[-1, 2000, 8000, 12000], labels=['low', 'med', 'high'])
combi['Room_Service_group']

combi['Room_Service_group'].replace({"low": 1, "med": 2, "high": 3},inplace=True)
combi['Room_Service_group']

#Food Court

combi['Food_Court_group'] = pd.cut(x=combi['FoodCourt'], bins=[-1, 5000, 20000, 30000], labels=['low', 'med', 'high'])
combi['Food_Court_group']

combi['Food_Court_group'].replace({"low": 1, "med": 2, "high": 3},inplace=True)
combi['Food_Court_group']

#Shopping Mall

combi['Shopping_group'] = pd.cut(x=combi['ShoppingMall'], bins=[-1, 2000, 8000, 13000], labels=['low', 'med', 'high'])
combi['Shopping_group']

combi['Shopping_group'].replace({"low": 1, "med": 2, "high": 3},inplace=True)
combi['Shopping_group']

#Spa

combi['Spa_group'] = pd.cut(x=combi['Spa'], bins=[-1, 5000, 15000, 23000], labels=['low', 'med', 'high'])
combi['Spa_group']

combi['Spa_group'].replace({"low": 1, "med": 2, "high": 3},inplace=True)
combi['Spa_group']

#VR Deck

combi['VR_group'] = pd.cut(x=combi['VRDeck'], bins=[-1, 5000, 15000, 23000], labels=['low', 'med', 'high'])
combi['VR_group']

combi['VR_group'].replace({"low": 1, "med": 2, "high": 3},inplace=True)
combi['VR_group']

#Assign features

combi.info()

combi.shape

combi = np.asarray(combi).astype('float32')

#Define X and y

features = ["HomePlanet", "CryoSleep", "Destination", "Age_group", "Room_Service_group", "Food_Court_group", "Shopping_group", "Spa_group", "VR_group"]

y = target
X = combi[features][: len(train1)]
X_test = combi[features][len(train1) :]

#https://keras.io/api/  (Keras Documentation)

import keras 
from keras.models import Sequential  #Sequencia entre as camadas: Entrada - Oculta - Saida
from keras.layers import Dense       #Iremos utilizar camadas densa na rede neural (full-connection)

#criar a rede neural sequencial 
ann = Sequential()

#definir as camadas de entrada, oculta 
ann.add( Dense(units = 10, activation = 'relu', kernel_initializer = 'random_uniform', input_dim=19))  #primeira camada oculta (nr_neuronios_entradas + nr_neuronios_saida / 2) = (30+1 / 2 = 16);  
                                                                                                       #input_dim = 30  (número de neuronios da camada de entrada = features de X_train)
#definir a camada de saida
ann.add(Dense(units = 1, activation = 'sigmoid'))

#configurar parâmetros da rede 
ann.compile(optimizer = 'adam',             #optimizer -> calculo dos ajustes dos pesos (descida do gradiente), calculo do delta
            loss='binary_crossentropy',     #loss -> calculo ou tratamento do erro      (binary_crossentropy -> para problemas de classificação binária)
            metrics = ['binary_accuracy']   #metrics -> avaliar a metrica do modelo ->   accuracy para problema de classificação binária 
           )

#treinar a rede neural
ann.fit(X, y, batch_size = 10, epochs = 50)